{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65381efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Define paths for train and test directories\n",
    "train_parquet_path = r'G:\\Major Project\\MRI\\Folder2\\Alzheimer MRI Disease Classification Dataset\\Data\\train-00000-of-00001-c08a401c53fe5312.parquet'\n",
    "test_parquet_path = r'G:\\Major Project\\MRI\\Folder2\\Alzheimer MRI Disease Classification Dataset\\Data\\test-00000-of-00001-44110b9df98c5585.parquet'\n",
    "\n",
    "# Define output directories for saving the images\n",
    "output_train_dir = r'G:\\Major Project\\MRI\\Folder2\\Alzheimer MRI Disease Classification Dataset\\Output\\train'\n",
    "output_test_dir = r'G:\\Major Project\\MRI\\Folder2\\Alzheimer MRI Disease Classification Dataset\\Output\\test'\n",
    "\n",
    "# Define categories as per the label\n",
    "categories = {\n",
    "    0: 'Mild_Demented',\n",
    "    1: 'Moderate_Demented',\n",
    "    2: 'Non_Demented',\n",
    "    3: 'Very_Mild_Demented'\n",
    "}\n",
    "\n",
    "# Function to decode image and save it\n",
    "def save_image(image_data, label, output_dir, index):\n",
    "    # Extract the byte string from the 'bytes' field in the dictionary\n",
    "    if isinstance(image_data, dict) and 'bytes' in image_data:\n",
    "        image_data = image_data['bytes']\n",
    "    else:\n",
    "        print(f\"Error: 'bytes' field not found for image {index}\")\n",
    "        return\n",
    "    \n",
    "    # Convert the byte string to a numpy array and decode as an image\n",
    "    nparr = np.frombuffer(image_data, np.uint8)\n",
    "    img = cv2.imdecode(nparr, cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    # Create the label folder if it doesn't exist\n",
    "    label_folder = os.path.join(output_dir, categories[label])\n",
    "    if not os.path.exists(label_folder):\n",
    "        os.makedirs(label_folder)\n",
    "\n",
    "    # Define the file path to save the image\n",
    "    image_path = os.path.join(label_folder, f'{index}.png')\n",
    "    \n",
    "    # Save the image\n",
    "    cv2.imwrite(image_path, img)\n",
    "\n",
    "# Function to process a Parquet file and extract images\n",
    "def process_parquet(parquet_path, output_dir):\n",
    "    # Read Parquet file into DataFrame\n",
    "    df = pd.read_parquet(parquet_path)\n",
    "    \n",
    "    # Iterate through each row in the DataFrame\n",
    "    for idx, row in df.iterrows():\n",
    "        image_data = row['image']  # Assuming the image data is in the 'image' column\n",
    "        label = row['label']  # Assuming the label is in the 'label' column\n",
    "        save_image(image_data, label, output_dir, idx)\n",
    "\n",
    "# Process the train Parquet file\n",
    "process_parquet(train_parquet_path, output_train_dir)\n",
    "\n",
    "# Process the test Parquet file\n",
    "process_parquet(test_parquet_path, output_test_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23994442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               image  label\n",
      "0  {'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...      2\n",
      "1  {'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...      0\n",
      "2  {'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...      3\n",
      "3  {'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...      3\n",
      "4  {'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...      2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the Parquet file into a DataFrame\n",
    "df = pd.read_parquet(train_parquet_path)\n",
    "\n",
    "# Print the first few rows to inspect the data structure\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ff23af8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Mild_Demented: 100%|██████████████████████████████████████████████████████| 724/724 [00:16<00:00, 43.90it/s]\n",
      "Processing Moderate_Demented: 100%|████████████████████████████████████████████████████| 49/49 [00:01<00:00, 24.56it/s]\n",
      "Processing Non_Demented: 100%|█████████████████████████████████████████████████████| 2566/2566 [00:52<00:00, 48.68it/s]\n",
      "Processing Very_Mild_Demented: 100%|███████████████████████████████████████████████| 1781/1781 [00:40<00:00, 44.34it/s]\n",
      "Processing Mild_Demented: 100%|██████████████████████████████████████████████████████| 172/172 [00:05<00:00, 31.23it/s]\n",
      "Processing Moderate_Demented: 100%|████████████████████████████████████████████████████| 15/15 [00:00<00:00, 16.20it/s]\n",
      "Processing Non_Demented: 100%|███████████████████████████████████████████████████████| 634/634 [00:15<00:00, 41.35it/s]\n",
      "Processing Very_Mild_Demented: 100%|█████████████████████████████████████████████████| 459/459 [00:09<00:00, 47.23it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define paths for train and test directories\n",
    "train_dir = r'G:\\Major Project\\MRI\\Folder2\\Alzheimer MRI Disease Classification Dataset\\Output\\train'\n",
    "test_dir = r'G:\\Major Project\\MRI\\Folder2\\Alzheimer MRI Disease Classification Dataset\\Output\\test'\n",
    "\n",
    "# Output directories for preprocessed images\n",
    "preprocessed_train_dir = r'G:\\Major Project\\MRI\\Folder2\\Alzheimer MRI Disease Classification Dataset\\Preprocessed\\train'\n",
    "preprocessed_test_dir = r'G:\\Major Project\\MRI\\Folder2\\Alzheimer MRI Disease Classification Dataset\\Preprocessed\\test'\n",
    "\n",
    "# Image dimensions for resizing\n",
    "IMG_SIZE = (128, 128)\n",
    "\n",
    "def preprocess_images(input_dir, output_dir, img_size):\n",
    "    \"\"\"\n",
    "    Preprocess images by resizing and normalizing them.\n",
    "\n",
    "    Args:\n",
    "    - input_dir (str): Path to the input directory.\n",
    "    - output_dir (str): Path to the output directory.\n",
    "    - img_size (tuple): Target image size (width, height).\n",
    "    \"\"\"\n",
    "    # Iterate through each category folder (e.g., Mild_Demented, Moderate_Demented)\n",
    "    for category in os.listdir(input_dir):\n",
    "        category_path = os.path.join(input_dir, category)\n",
    "        output_category_path = os.path.join(output_dir, category)\n",
    "\n",
    "        # Create the category output folder if it doesn't exist\n",
    "        if not os.path.exists(output_category_path):\n",
    "            os.makedirs(output_category_path)\n",
    "\n",
    "        # Process each image in the category folder\n",
    "        for img_name in tqdm(os.listdir(category_path), desc=f\"Processing {category}\"):\n",
    "            img_path = os.path.join(category_path, img_name)\n",
    "            \n",
    "            # Read the image\n",
    "            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "            # Check if the image is valid\n",
    "            if img is None:\n",
    "                print(f\"Skipping invalid image: {img_path}\")\n",
    "                continue\n",
    "            \n",
    "            # Resize the image\n",
    "            img_resized = cv2.resize(img, img_size)\n",
    "\n",
    "            # Normalize the image (scale pixel values to [0, 1])\n",
    "            img_normalized = img_resized / 255.0\n",
    "\n",
    "            # Save the preprocessed image\n",
    "            output_path = os.path.join(output_category_path, img_name)\n",
    "            cv2.imwrite(output_path, (img_normalized * 255).astype(np.uint8))  # Save as 8-bit image\n",
    "\n",
    "            \n",
    "# Preprocess train dataset\n",
    "preprocess_images(train_dir, preprocessed_train_dir, IMG_SIZE)\n",
    "\n",
    "# Preprocess test dataset\n",
    "preprocess_images(test_dir, preprocessed_test_dir, IMG_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e881ec7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa7ef2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
